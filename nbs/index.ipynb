{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CubicGalileonEmu\n",
    "\n",
    "> GP emulator for boost factor in cubic Galileon gravity model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified Gravity emulator for boost in the dark matter power spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(not installable yet)\n",
    "```sh\n",
    "pip install CubicGalileonEmu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic rundown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CubicGalileonEmu.load import *\n",
    "from CubicGalileonEmu.viz import *\n",
    "from CubicGalileonEmu.pca import *\n",
    "from CubicGalileonEmu.gp import *\n",
    "from CubicGalileonEmu.emu import *\n",
    "from CubicGalileonEmu.mcmc import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "if_train_all = False ## Re-train all the models. Time-consuming. \n",
    "if_mcmc_all = False  ## Full MCMC run. Time-consuming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bk_all, k_all, z_all = load_boost_training()\n",
    "p_all = load_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few plotting routines\n",
    "\n",
    "#### Experimental design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_a = pd.DataFrame(p_all, columns=PARAM_NAME)\n",
    "colors = ['b']*p_all.shape[0]\n",
    "# colors = ['b']*num_sims + ['r']*num_sims_test\n",
    "plot_scatter_matrix(df_train_a, colors);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boost metrics colored by cosmology parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_by_index = 4\n",
    "z_index = 0\n",
    "\n",
    "plot_lines_with_param_color(p_all[:, color_by_index], \n",
    "                            k_all, \n",
    "                            Bk_all[:, z_index, :], \n",
    "                            'Training data, z=' + str(z_all[z_index]), \n",
    "                            r'$k [h/Mpc]$', \n",
    "                            r'$B(k)$', \n",
    "                            PARAM_NAME[color_by_index]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_by_index = 3\n",
    "z_index = 21\n",
    "\n",
    "plot_lines_with_param_color(p_all[:, color_by_index], \n",
    "                            k_all, \n",
    "                            Bk_all[:, z_index, :], \n",
    "                            'Training data, z=' + str(z_all[z_index]), \n",
    "                            r'$k [h/Mpc]$', \n",
    "                            r'$B(k)$', \n",
    "                            PARAM_NAME[color_by_index]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_index = 0\n",
    "\n",
    "f = plot_lines_with_param_color(z_all, \n",
    "                            k_all, \n",
    "                            Bk_all[16, :, :], \n",
    "                            'Training data', \n",
    "                            r'$k [h/Mpc]$', \n",
    "                            r'$B(k)$', \n",
    "                            'redshift');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training involves: PCA, GP fitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data prep\n",
    "z_index = 1\n",
    "y_vals = Bk_all[:, z_index, :]\n",
    "# y_ind = np.arange(0, y_vals.shape[1])\n",
    "y_ind = k_all\n",
    "\n",
    "# Train-test split\n",
    "test_indices = [0, 14, 35]\n",
    "input_params= p_all[test_indices]\n",
    "target_vals = Bk_all[:, z_index, :][test_indices]\n",
    "\n",
    "train_indices = [i for i in  np.arange(49) if i not in test_indices] \n",
    "p_all_train = p_all[train_indices]\n",
    "y_vals_train = Bk_all[:, z_index, :][train_indices]\n",
    "print('Redshift: ' + str(z_all[z_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepia_data = sepia_data_format(p_all_train, y_vals_train, y_ind)\n",
    "print(sepia_data)\n",
    "model_filename = '../CubicGalileonEmu/model/multivariate_model_z_index' + str(z_index) \n",
    "\n",
    "sepia_model = do_pca(sepia_data, exp_variance=0.95)\n",
    "sepia_model = do_gp_train(sepia_model, model_filename)\n",
    "plot_train_diagnostics(sepia_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepia_model = gp_load(sepia_model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-redshift emulation for new cosmological parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean, pred_quant = emulate(sepia_model, input_params)\n",
    "# pred_quant == Emulated (0.05, 0.95) quantile\n",
    "validation_plot(k_all, target_vals, pred_mean, pred_quant, xy_lims=[2e-2, 1e1, 0.98, 1.35]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity analysis from the emulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sensitivity_plot(k_all, p_all, sepia_model, emulate, PARAM_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-redshift emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if if_train_all:\n",
    "    \n",
    "    do_gp_train_multiple(model_dir='../CubicGalileonEmu/model/', \n",
    "                        p_train_all = p_all[train_indices],\n",
    "                        y_vals_all = Bk_all[train_indices],\n",
    "                        y_ind_all = k_all,\n",
    "                        z_index_range=range(49))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all trained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepia_model_list = load_model_multiple(model_dir='../CubicGalileonEmu/model/', \n",
    "                                        p_train_all=p_all[train_indices],\n",
    "                                        y_vals_all=Bk_all[train_indices],\n",
    "                                        y_ind_all=k_all,\n",
    "                                        z_index_range=range(49), \n",
    "                                        sepia_model_i=sepia_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Emulator with intermediate redshift input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_params0 = input_params[0]\n",
    "z_inputs = 0.05\n",
    "input_params_and_redshift = np.append(input_params0, z_inputs)\n",
    "print(input_params_and_redshift[np.newaxis, :])\n",
    "\n",
    "\n",
    "emulated_with_redshift, emulated_with_redshift_err = emu_redshift(input_params_and_redshift[np.newaxis, :], sepia_model_list, z_all)\n",
    "## There is an unknown issue with z_index=5 model, (sepia_model_list[6])\n",
    "emulate(sepia_model_list[6], input_params_and_redshift[:-1])[0]\n",
    "\n",
    "\n",
    "plt.figure(433)\n",
    "plt.plot(k_all, emulated_with_redshift[:, 0], label='interp at z=%.4f'%input_params_and_redshift[-1], lw=5, ls='--')\n",
    "plt.plot(k_all, emulate(sepia_model_list[0], input_params_and_redshift[:-1])[0], label='grid z=%.4f'%z_all[2])\n",
    "plt.plot(k_all, emulate(sepia_model_list[1], input_params_and_redshift[:-1])[0], label='grid z=%.4f'%z_all[3])\n",
    "plt.legend()\n",
    "plt.title('Comparison of redshift-space interpolation')\n",
    "# plt.plot(k_all, emulate(sepia_model_list[0], input_params))\n",
    "# plt.plot(k_all, emulate(sepia_model_list[0], input_params))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emulator confidence across "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter settings\n",
    "steps = 40  # Number of steps in the grid for each parameter\n",
    "param_name_extended = np.append(PARAM_NAME, 'Redshift')\n",
    "\n",
    "param_min = np.append(p_all.min(axis=0), 0)\n",
    "param_max = np.append(p_all.max(axis=0), 3)\n",
    "param_mean = np.append(p_all.mean(axis=0), 1.0)\n",
    "\n",
    "# Compute outputs and errors for a range of parameter values\n",
    "def compute_errors(param_grid):\n",
    "    errors = np.array([np.mean(emu_redshift(params[np.newaxis, :], sepia_model_list, z_all)[1][:, 0, :]**2)\n",
    "                       for params in param_grid])\n",
    "    return errors.reshape(steps, steps)\n",
    "\n",
    "# Example usage:\n",
    "param_indices = [4, 5]  # Indices of parameters to vary\n",
    "fixed_indices = [i for i in range(len(param_name_extended)) if i not in param_indices]\n",
    "fixed_params = {param_name_extended[i]: param_mean[i] for i in fixed_indices}\n",
    "\n",
    "param_grid = generate_param_grid_with_fixed(param_name_extended, param_indices, fixed_params, param_min, param_max, steps)\n",
    "errors = compute_errors(param_grid)\n",
    "f = plot_error_heatmap(errors, [param_name_extended[i] for i in param_indices], [(param_min[param_indices[0]], param_max[param_indices[0]]), (param_min[param_indices[1]], param_max[param_indices[1]])])\n",
    "\n",
    "# f.savefig('../../../Plots/heatmap_params_4_5.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter inference via MCMC using the emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 5\n",
    "nwalkers = 50  # 500\n",
    "nrun_burn = 100  # 300\n",
    "nrun = 1000  # 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating mock observational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_indx = 0 #0 ,14, 35\n",
    "z_index = 4\n",
    "L = 32\n",
    "fake_obs_data_index_every = 2\n",
    "\n",
    "redshift = z_all[z_index]\n",
    "x = k_all[::fake_obs_data_index_every]\n",
    "y = Bk_all[:, z_index, :][target_indx][::fake_obs_data_index_every]\n",
    "y = y + 1e-3*np.random.normal(0.0, 1.0, size=y.shape)\n",
    "yerr = np.sqrt( Bk_all[:, z_index, :][target_indx][::fake_obs_data_index_every]*(L**3))/(L**3)\n",
    "\n",
    "x_grid = k_all\n",
    "params_calib = p_all[target_indx][:, np.newaxis].T\n",
    "print('redshift: ', redshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f, a = plt.subplots(1,1, figsize = (8, 5)) \n",
    "input_params_and_redshift = np.append(params_calib, redshift)\n",
    "bk_target, err_target = emu_redshift(input_params_and_redshift[np.newaxis, :], sepia_model_list, z_all)\n",
    "a.plot(k_all, bk_target[:, 0], label='Emulated at target params', lw=5, ls='--')\n",
    "a.errorbar(x, y, yerr, label='Target mock observations', ls='none', lw=1, color = \"r\")\n",
    "a.scatter(x, y, s = 5, marker = \"h\", color = \"r\")\n",
    "\n",
    "\n",
    "a.plot(k_all, Bk_all[:, z_index, :].T, 'k', alpha=0.1)\n",
    "\n",
    "\n",
    "plt.plot(k_all, emulate(sepia_model_list[z_index], input_params_and_redshift[:-1])[0], label='grid z=%.4f'%z_all[z_index])\n",
    "plt.plot(k_all, emulate(sepia_model_list[z_index+1], input_params_and_redshift[:-1])[0], label='grid z=%.4f'%z_all[z_index + 1])\n",
    "\n",
    "string_print0 = 'Target Params \\n\\n' \n",
    "string_print1 = PARAM_NAME[0] + '= %.4f'%input_params_and_redshift[0] + '\\n'\n",
    "string_print2 = PARAM_NAME[1] + '= %.4f'%input_params_and_redshift[1] + '\\n'\n",
    "string_print3 = PARAM_NAME[2] + '= %.4f'%input_params_and_redshift[2] + '\\n'\n",
    "string_print4 = PARAM_NAME[3] + '= %.4f'%input_params_and_redshift[3] + '\\n'\n",
    "string_print5 = PARAM_NAME[4] + '= %.4f'%input_params_and_redshift[4] + '\\n'\n",
    "string_print6 = 'redshift' + '= %.4f'%input_params_and_redshift[5] \n",
    "\n",
    "\n",
    "string_print = string_print0 + string_print1 + string_print2 + string_print3 + string_print4 + string_print5 + string_print6\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='gray', alpha=0.2)\n",
    "plt.text(1.02, 0.1, string_print, transform=a.transAxes, fontsize=12, bbox=props)\n",
    "\n",
    "\n",
    "a.set_xscale('log')\n",
    "plt.title('pre-MCMC')\n",
    "a.set_xlabel(r'$k [h/Mpc]$')\n",
    "a.set_ylabel(r'$B(k)$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allMax = np.max(p_all, axis = 0)\n",
    "allMin = np.min(p_all, axis = 0)\n",
    "\n",
    "param1 = [PARAM_NAME[0], params_calib[0][0], allMin[0], allMax[0]] \n",
    "param2 = [PARAM_NAME[1], params_calib[0][1], allMin[1], allMax[1]]\n",
    "param3 = [PARAM_NAME[2], params_calib[0][2], allMin[2], allMax[2]]\n",
    "param4 = [PARAM_NAME[3], params_calib[0][3], allMin[3], allMax[2]]\n",
    "param5 = [PARAM_NAME[4], params_calib[0][4], allMin[4], allMax[4]]\n",
    "\n",
    "params_list = [param1, param2, param3, param4, param5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos0 = chain_init(params_list, ndim, nwalkers)\n",
    "sampler = define_sampler(redshift, ndim, nwalkers, params_list, x_grid, sepia_model_list, z_all, x, y, yerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MCMC run - first burn, then full. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos, prob, state, samples, sampler, autocorr, index = do_mcmc(sampler, pos0, nrun_burn, ndim, if_burn=True)\n",
    "\n",
    "if if_mcmc_all: # Full MCMC-run, will be slow\n",
    "    pos, prob, state, samples, sampler, autocorr, index = do_mcmc(sampler, pos, nrun, ndim, if_burn=False)\n",
    "\n",
    "p_mcmc = mcmc_results(samples)\n",
    "\n",
    "fig = plot_mcmc(samples, params_list, if_truth_know=True)\n",
    "# plt.savefig('../../../Plots/mcmc_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f, a = plt.subplots(1,1, figsize = (8, 5)) \n",
    "input_params_and_redshift = np.append(p_mcmc, redshift)\n",
    "bk_mcmc, err_mcmc = emu_redshift(input_params_and_redshift[np.newaxis, :], sepia_model_list, z_all)\n",
    "a.plot(k_all, bk_mcmc[:, 0], label='Emulated at best MCMC', lw=3, ls='--')\n",
    "a.errorbar(x, y, yerr, label='Mock target', ls='none', lw=1, color = \"r\")\n",
    "a.scatter(x, y, s = 5, marker = \"h\", color = \"r\", alpha=0.5)\n",
    "\n",
    "a.plot(k_all, Bk_all[:, z_index, :].T, 'k', alpha=0.1)\n",
    "\n",
    "\n",
    "# plt.plot(k_all, emulate(sepia_model_list[z_index], input_params_and_redshift[:-1])[0], label='Z1')\n",
    "# plt.plot(k_all, emulate(sepia_model_list[z_index+1], input_params_and_redshift[:-1])[0], label='Z2')\n",
    "\n",
    "string_print0 = 'Target Params \\n\\n' \n",
    "string_print1 = PARAM_NAME[0] + '= %.3f'%params_calib[0][0] + '\\n'\n",
    "string_print2 = PARAM_NAME[1] + '= %.3f'%params_calib[0][1] + '\\n'\n",
    "string_print3 = PARAM_NAME[2] + '= %.3f'%params_calib[0][2] + '\\n'\n",
    "string_print4 = PARAM_NAME[3] + '= %.3f'%params_calib[0][3] + '\\n'\n",
    "string_print5 = PARAM_NAME[4] + '= %.3f'%params_calib[0][4] + '\\n'\n",
    "string_print6 = 'redshift' + '= %.3f'%redshift\n",
    "\n",
    "\n",
    "string_print = string_print0 + string_print1 + string_print2 + string_print3 + string_print4 + string_print5 + string_print6\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='gray', alpha=0.2)\n",
    "plt.text(1.02, 0.5, string_print, transform=a.transAxes, fontsize=12, bbox=props)\n",
    "\n",
    "string_print0_mcmc = 'Optimized Params \\n\\n' \n",
    "string_print1_mcmc = PARAM_NAME[0] + '= %.3f'%p_mcmc[0] + '\\n'\n",
    "string_print2_mcmc = PARAM_NAME[1] + '= %.3f'%p_mcmc[1] + '\\n'\n",
    "string_print3_mcmc = PARAM_NAME[2] + '= %.3f'%p_mcmc[2] + '\\n'\n",
    "string_print4_mcmc = PARAM_NAME[3] + '= %.3f'%p_mcmc[3] + '\\n'\n",
    "string_print5_mcmc = PARAM_NAME[4] + '= %.3f'%p_mcmc[4] \n",
    "\n",
    "string_print_mcmc = string_print0_mcmc + string_print1_mcmc + string_print2_mcmc + string_print3_mcmc + string_print4_mcmc + string_print5_mcmc\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='blue', alpha=0.2)\n",
    "plt.text(1.02, 0.05, string_print_mcmc, transform=a.transAxes, fontsize=12, bbox=props)\n",
    "\n",
    "\n",
    "\n",
    "a.set_xscale('log')\n",
    "plt.title('B(k) at MCMC constraints')\n",
    "a.set_xlabel(r'$k [h/Mpc]$')\n",
    "a.set_ylabel(r'$B(k)$')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "\n",
    "if if_mcmc_all:\n",
    "    tau = sampler.get_autocorr_time(tol=0)\n",
    "    print(tau)\n",
    "\n",
    "    plt.figure(43)\n",
    "    plt.plot(prob)\n",
    "    # plt.savefig('../../../Plots/prob_plot.png', bbox_inches='tight')\n",
    "\n",
    "    selected_indices_for_plot = [0, 2, 4]\n",
    "    fig = plot_mcmc(samples[:, selected_indices_for_plot], [params_list[i] for i in selected_indices_for_plot], if_truth_know=True)\n",
    "\n",
    "    # plt.savefig('../../../Plots/mcmc_plot_reduced_params.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "if if_mcmc_all:\n",
    "\n",
    "    n = 100 * np.arange(1, index + 1)\n",
    "    y = autocorr[:index]\n",
    "    plt.plot(n, n / 100.0, \"--k\")\n",
    "    plt.plot(n, y)\n",
    "    plt.xlim(0, n.max())\n",
    "    plt.ylim(0, y.max() + 0.1 * (y.max() - y.min()))\n",
    "    plt.xlabel(\"number of steps\")\n",
    "    plt.ylabel(r\"mean $\\hat{\\tau}$\");\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "if if_mcmc_all:\n",
    "    plt.plot(autocorr)\n",
    "    plt.xscale('log')\n",
    "    # plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
